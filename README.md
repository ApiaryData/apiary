# ğŸ Apiary

> A distributed data processing framework inspired by bee colony intelligence, designed for small compute that scales to the cloud.

[![CI](https://github.com/ApiaryData/apiary/actions/workflows/ci.yml/badge.svg)](https://github.com/ApiaryData/apiary/actions/workflows/ci.yml)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Rust](https://img.shields.io/badge/Rust-1.78%2B-orange.svg)](https://www.rust-lang.org/)
[![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)](https://www.python.org/)

## What Is Apiary?

Apiary is a **lakehouse for small compute**. It's designed to run on inexpensive hardware â€” Raspberry Pis, NUCs, old laptops â€” while scaling seamlessly to cloud compute. Users write data via Python, query via SQL, and the swarm distributes work across available nodes with no central controller.

### Key Features

- **ğŸ¡ Runs on Small Hardware**: Designed for Raspberry Pi and similar devices, not cloud-first systems squeezed onto small hardware
- **â˜ï¸ Object Storage as Truth**: Data lives in S3, GCS, MinIO, or local filesystem â€” nodes are stateless workers
- **ğŸ¤ No Node-to-Node Communication**: Nodes coordinate through the storage layer itself, eliminating distributed systems complexity
- **ğŸ”’ ACID Transactions**: Ledger-based transactions using conditional writes (like Delta Lake)
- **ğŸ Biology-Driven Design**: Memory budgets, task sizing, and failure recovery governed by bee-inspired behavioral patterns
- **ğŸ“Š SQL Queries**: Apache DataFusion powers SQL queries over Parquet files
- **ğŸ Python Interface**: PyO3-based SDK with zero-copy Arrow interop
- **ğŸš€ Zero Configuration Multi-Node**: Add nodes by connecting to the same storage bucket â€” no seed nodes, no tokens

## What Makes Apiary Different

1. **Small-compute-first design**: Not a cloud system squeezed onto a Pi, but a system designed for resource-constrained hardware that scales to the cloud.

2. **Object storage as coordination layer**: No consensus protocol, no gossip network, no node-to-node communication. Nodes coordinate through the same storage that holds the data.

3. **Biology-driven resource management**: Memory budgets, cell sizing, backpressure, and failure recovery are governed by bee-inspired behavioral patterns â€” not metaphors, but algorithms.

4. **Zero-configuration multi-node**: A second node joins the swarm by connecting to the same storage bucket. No seed nodes, no tokens, no mesh network setup.

5. **Solo to swarm without code changes**: A single Pi with local filesystem storage is a fully functional data platform. Switching to S3 and adding nodes is a configuration change, not an architecture change.

## Quick Start

### Installation

#### Pre-built Binaries (no build required)

```bash
# Linux / macOS (x86_64 or ARM64 / Raspberry Pi)
curl -fsSL https://raw.githubusercontent.com/ApiaryData/apiary/main/scripts/install.sh | bash
```

```powershell
# Windows (PowerShell)
irm https://raw.githubusercontent.com/ApiaryData/apiary/main/scripts/install.ps1 | iex
```

#### Docker

```bash
docker pull ghcr.io/apiarydata/apiary:latest   # or build locally
docker build -t apiary:latest .
```

#### Build from Source

**Prerequisites**: Rust 1.78+, Python 3.9+

```bash
git clone https://github.com/ApiaryData/apiary.git
cd apiary
cargo build --workspace
pip install maturin
maturin develop
```

### Hello Apiary

```python
from apiary import Apiary

# Solo mode (local filesystem)
ap = Apiary("my_database")
ap.start()

# Check status
status = ap.status()
print(f"Running on {status['cores']} cores with {status['memory_gb']:.2f}GB memory")

# Shutdown when done
ap.shutdown()
```

### Multi-Node Mode

```python
from apiary import Apiary

# All nodes connect to the same storage
ap = Apiary("production", storage="s3://my-bucket/apiary")
ap.start()

# Nodes automatically discover each other through the storage layer
# No additional configuration needed!
```

## Architecture Overview

### The Beekeeping Metaphor

| Concept | Apiary Component | Description |
|---------|------------------|-------------|
| **Hive** | Database | Top-level logical grouping |
| **Box** | Schema | Namespace within a hive |
| **Frame** | Table | Queryable dataset |
| **Cell** | Parquet file | Physical storage unit |
| **Bee** | CPU core | Unit of compute (1 core = 1 bee) |
| **Swarm** | Compute mesh | All nodes and their bees |
| **Meadow** | Object storage | Where all data lives |

### Storage Model

```
Tier 1 â€” Memory: Arrow RecordBatches in bee chambers (active computation)
Tier 2 â€” Local Disk: Cache + spill + write buffer
Tier 3 â€” Object Storage: S3/GCS/MinIO/filesystem (canonical truth)
```

### Key Design Principles

- **Object storage is canonical**: All committed data, metadata, and coordination state lives in object storage
- **Conditional writes for serialization**: One write succeeds, the other retries â€” no Raft needed
- **1 core = 1 bee**: Each virtual core is an independent unit with its own memory budget
- **Biology is the runtime**: Mason bee isolation, leafcutter sizing, abandonment, and colony temperature are not metaphors but algorithms

## Development Status

Apiary is in active development. See [BUILD_STATUS.md](BUILD_STATUS.md) for detailed progress.

| Step | Component | Status |
|------|-----------|--------|
| 1 | Skeleton + StorageBackend | âœ… Complete |
| 2 | Registry + Namespace | âœ… Complete |
| 3 | Ledger + Cell Storage | âœ… Complete |
| 4 | DataFusion Integration | âœ… Complete |
| 5 | Mason Bee Isolation | âœ… Complete |
| 6 | Heartbeat + World View | âœ… Complete |
| 7 | Distributed Query Execution | âœ… Complete |
| 8 | Local Cell Cache | âœ… Complete |
| 9 | Behavioral Model | âœ… Complete |
| 10 | Testing + Hardening | âœ… Complete |

### Current Capabilities (Step 10 Complete â€” v1 Release Candidate)

- âœ… Rust workspace with 6 crates
- âœ… Python SDK via PyO3
- âœ… LocalBackend (filesystem storage)
- âœ… S3Backend (S3-compatible object storage)
- âœ… StorageBackend trait with atomic operations
- âœ… Node configuration with resource auto-detection
- âœ… Typed identifiers (HiveId, BoxId, FrameId, TaskId, etc.)
- âœ… Registry with DDL operations (create/list hives, boxes, frames)
- âœ… Dual terminology (bee-themed and traditional database naming)
- âœ… Transaction ledger with optimistic concurrency
- âœ… Parquet cell writing with LZ4 compression
- âœ… Cell-level statistics for query pruning
- âœ… Partitioning with partition pruning on read
- âœ… Leafcutter cell sizing
- âœ… Schema validation (null partition rejection)
- âœ… Frame overwrite (atomic cell replacement)
- âœ… Ledger checkpointing
- âœ… SQL queries via Apache DataFusion
- âœ… Custom SQL commands (USE, SHOW, DESCRIBE)
- âœ… Cell pruning from WHERE predicates
- âœ… Projection pushdown via DataFusion
- âœ… Aggregation (GROUP BY, AVG, SUM, COUNT, MIN, MAX)
- âœ… DML blocking (DELETE/UPDATE with clear error messages)
- âœ… Mason bee sealed chambers (memory-budgeted isolated execution per bee)
- âœ… BeePool with task queuing and concurrent execution
- âœ… Task timeout enforcement
- âœ… Scratch directory isolation per bee
- âœ… SQL queries routed through BeePool
- âœ… Heartbeat writer (background task writing node status to storage)
- âœ… World view builder (discovers all nodes via heartbeat polling)
- âœ… Node state detection (Alive, Suspect, Dead based on heartbeat age)
- âœ… Graceful departure (heartbeat file deleted on shutdown)
- âœ… Stale heartbeat cleanup (dead nodes cleaned after threshold)
- âœ… `swarm_status()` Python API for swarm visibility
- âœ… Solo mode works as a swarm of one (zero special-casing)
- âœ… Distributed query planner (cache-aware, capacity-based cell assignment)
- âœ… Query coordinator (manifest writing, task execution, result merging)
- âœ… Worker task poller (background task polling for query manifests)
- âœ… Storage-based coordination (query manifests via object storage)
- âœ… Partial result exchange (Arrow IPC format)
- âœ… Transparent distribution (single-node fallback for small queries)
- âœ… Local cell cache (LRU eviction, 2GB default)
- âœ… Cache reporting in heartbeats (enables cache-aware planning)
- âœ… Cache-aware distributed query planning (preferential assignment)
- âœ… Colony temperature measurement (composite system health metric)
- âœ… Temperature regulation classification (cold/ideal/warm/hot/critical)
- âœ… Task abandonment tracker (retry logic with trial limits)
- âœ… Behavioral model Python API (colony_status method)

- âœ… Integration tests (solo mode, multi-node, mason isolation, concurrent writes, backpressure, chaos)
- âœ… Documentation (getting started, concepts, Python SDK, SQL reference, architecture summary)

## Project Structure

```
apiary/
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ apiary-core/       # Core types and traits
â”‚   â”œâ”€â”€ apiary-storage/    # Storage backends
â”‚   â”œâ”€â”€ apiary-runtime/    # Node runtime
â”‚   â”œâ”€â”€ apiary-query/      # DataFusion SQL engine
â”‚   â”œâ”€â”€ apiary-python/     # PyO3 bindings
â”‚   â””â”€â”€ apiary-cli/        # Command-line interface
â”œâ”€â”€ python/                # Python package source
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture/      # Design documentation
â””â”€â”€ test_step*_acceptance.py  # Acceptance tests
```

## Technology Stack

| Component | Technology | Why |
|-----------|-----------|-----|
| Runtime | Rust | Memory safety, zero-cost abstractions, ARM64 cross-compilation |
| Python Bridge | PyO3 + maturin | Zero-copy Arrow interop, native wheels |
| SQL Engine | Apache DataFusion | Rust-native, Arrow-native, extensible |
| Storage Format | Apache Parquet | Columnar, compressed, universal |
| In-Memory | Apache Arrow | Zero-copy, columnar, cross-language |
| Object Storage | S3 API | Universal, battle-tested |
| Async Runtime | Tokio | Standard Rust async |

## Development

### Build

```bash
# Build all Rust crates
cargo build --workspace

# Run tests
cargo test --workspace

# Run linter
cargo clippy --workspace

# Build Python package
maturin develop
```

### Run Tests

```bash
# Rust tests
cargo test --workspace

# Python acceptance tests
python test_step1_acceptance.py
```

## Contributing

Apiary is in early development. Contributions are welcome once the v1 core is established. For now, watch the repository and join the conversation in issues.

## Roadmap

### v1 â€” Prove the Core (In Progress)

- Single-node and multi-node operation
- Python SDK with data writing
- SQL queries via DataFusion
- ACID transactions via conditional writes
- Distributed query execution
- Mason bee isolation and leafcutter sizing

### v2 â€” Direct Communication

- SWIM (Scalable Weakly-consistent Infection-style Membership) gossip for sub-second failure detection
- Arrow Flight for low-latency data shuffles
- Full 20-behavior biological model
- Streaming ingestion
- Time travel queries

### v3 â€” Enterprise & Federation

- Multi-apiary federation
- Regulatory compliance
- Data lineage
- Advanced access control

See [docs/architecture/06-roadmap.md](docs/architecture/06-roadmap.md) for details.

## Documentation

### Getting Started
- [Getting Started](docs/getting-started.md)
- [Concepts](docs/concepts.md)

### Deployment Guides
- [Quick Deployment Guide](docs/deployment-quickstart.md) â€” Fast setup for Pi and containers
- [Raspberry Pi Deployment](docs/deployment-raspberry-pi.md) â€” Complete guide for edge devices
- [Cloud Container Deployment](docs/deployment-containers.md) â€” Docker and Kubernetes

### API & SQL
- [Python SDK Reference](docs/python-sdk.md)
- [SQL Reference](docs/sql-reference.md)

### Architecture
- [Architecture Summary](docs/architecture-summary.md)
- [Architecture Overview](docs/architecture/01-architecture-overview.md)
- [Storage Engine](docs/architecture/02-storage-engine.md)
- [Swarm Coordination](docs/architecture/03-swarm-coordination.md)
- [Query Execution](docs/architecture/04-query-execution.md)
- [Behavioral Model](docs/architecture/05-behavioral-model.md)
- [Roadmap](docs/architecture/06-roadmap.md)

## License

Apache License 2.0 - See [LICENSE](LICENSE) for details.

## Acknowledgments

Apiary draws inspiration from:
- The biological intelligence of bee colonies
- Apache Arrow ecosystem (DataFusion, Parquet, object_store)
- Delta Lake's transaction log design
- Modern lakehouse architectures

---

**Status**: v1 Release Candidate. All 10 steps complete. ğŸ